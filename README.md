# Google-GenAI-Intensive-Course ğŸ“
# Resources, Notes, and Projects from Google's 5-Day Generative AI Intensive Course ğŸ“š

This GitHub page gathers all the resources shared during the 5-Day Generative AI Intensive course. I came across this course randomly and found it comes with great resources.

Among these resources are whitepapers by Google experts, Kaggle LLM notebooks, and hours of YouTube live streams by the same Google team. Pretty cool stuff. ğŸ‘

I have compiled a list of resources by day and organized them by type (e.g., whitepapers, Kaggle notebooks, YouTube live streams).

**YouTube LiveStream:** â–¶ï¸ [Playlist](https://www.youtube.com/playlist?list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es)

**Kaggle:** ğŸ“Š [Event Page](https://rsvp.withgoogle.com/events/google-generative-ai-intensive/home)

**Kaggle Whitepaper Companion Playlist:** ğŸ“‚ [Playlist](https://www.youtube.com/playlist?list=PLqFaTIg4myu8GFXsSEicf6q_ExhfOr5ck)

---
## List of Notebooks

- **Day 1: Foundational Large Language Models & Text Generation**
  - [Prompting Fundamentals](https://www.kaggle.com/code/markishere/day-1-prompting)

- **Day 2: Embeddings and Vector Stores/Databases**
  - [Build a RAG Question-Answering System Over Custom Documents](https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag)
  - [Explore Text Similarity with Embeddings](https://www.kaggle.com/code/markishere/day-2-embeddings-and-similarity-scores)
  - [Build a Neural Classification Network with Keras Using Embeddings](https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras)

- **Day 3: Generative AI Agents**
  - [Talk to a Database with Function Calling](https://www.kaggle.com/code/markishere/day-3-function-calling-with-the-gemini-api)
  - [Build an Agentic Ordering System in LangGraph](https://www.kaggle.com/code/markishere/day-3-building-an-agent-with-langgraph)

- **Day 4: Domain-Specific LLMs**
  - [Use Google Search Data in Generation](https://www.kaggle.com/code/markishere/day-4-google-search-grounding)
  - [Tune a Gemini Model for a Custom Task](https://www.kaggle.com/code/markishere/day-4-fine-tuning-a-custom-model)

---
## List of Whitepapers

- **Day 1: Foundational Large Language Models & Text Generation**
  - [Foundational Large Language Models & Text Generation](https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation)
  - [Prompt Engineering](https://www.kaggle.com/whitepaper-prompt-engineering)

- **Day 2: Embeddings and Vector Stores/Databases**
  - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
  - [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
  - [NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models](https://arxiv.org/abs/2405.17428)
  - [Native Integration of the ScaNN Algorithm into AlloyDB Database Internals](https://services.google.com/fh/files/misc/scann_for_alloydb_whitepaper.pdf)
  - [Embeddings and Vector Stores/Databases](https://www.kaggle.com/whitepaper-embeddings-and-vector-stores)

- **Day 3: Generative AI Agents**
  - [Generative AI Agents](https://www.kaggle.com/whitepaper-agents)

- **Day 4: Domain-Specific LLMs**
  - [Solving Domain-Specific Problems Using LLMs](https://www.kaggle.com/whitepaper-solving-domains-specific-problems-using-llms)

- **Day 5: MLOps for Generative AI**
  - [Gecko: Text-to-Image Evaluation](https://arxiv.org/abs/2404.16820)
  - [MLOps for Generative AI](https://www.kaggle.com/whitepaper-operationalizing-generative-ai)

---

## Day 1: Foundational Large Language Models & Text Generation and Prompt Engineering ğŸš€

â¡ï¸ Listen to Day 1 Live stream ğŸ§ [Day 1 Livestream with Paige Bailey â€“ 5-Day Gen AI Intensive Course | Kaggle](https://www.youtube.com/watch?v=mQDlCZZsOyo&t=0s) 
â¡ï¸ Listen to the summary podcast episode: ğŸ§ [Whitepaper Companion Podcast - Foundational LLMs](https://www.youtube.com/watch?v=mQDlCZZsOyo&t=0s) 

â¡ï¸ Read the â€œFoundational Large Language Models & Text Generationâ€ whitepaper: ğŸ“„ [https://www.kaggle.com/whitepaper-fou...](https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation)

Unit 1 - â€œPrompt Engineeringâ€:

â¡ï¸ Listen to the summary podcast episode: ğŸ§ [Whitepaper Companion Podcast - Prompt Engineering](https://www.youtube.com/watch?v=1CC39K76Nqs&t=0s)

â¡ï¸ Read the â€œPrompt Engineeringâ€ whitepaper: ğŸ“„ [https://www.kaggle.com/whitepaper-pro...](https://www.kaggle.com/whitepaper-prompt-engineering)

â¡ï¸ Complete this code lab on Kaggle where you'll learn prompting fundamentals: ğŸ’» [https://www.kaggle.com/code/markisher...](https://www.kaggle.com/code/markishere/day-1-prompting)


---

## Day 2: Embeddings and Vector Stores/Databases ğŸ—ƒï¸

**Resources mentioned in today's livestream:**

- **Jinhyuk Lee's Google Scholar Profile:** ğŸ“š [ https://scholar.google.com/citations?... ](https://scholar.google.com/citations?user=YWm_zVcAAAAJ&hl=en)

- **The Original Transformer Paper:** ğŸ“„ [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

- **BERT Paper Explaining Bidirectional Attention:** ğŸ“„ [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

- **NV-Embed Paper:** ğŸ“„ [NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models](https://arxiv.org/abs/2405.17428)

- **Whitepaper:** ğŸ“„ [Native Integration of the ScaNN Algorithm into AlloyDB Database Internals](https://services.google.com/fh/files/misc/scann_for_alloydb_whitepaper.pdf)

**Assignments:**

â¡ï¸ Listen to the summary podcast episode: ğŸ§ [Whitepaper Companion Podcast - Embeddings and Vector Stores](https://www.youtube.com/watch?v=1CC39K76Nqs)

â¡ï¸ Read the â€œEmbeddings and Vector Stores/Databasesâ€ whitepaper: ğŸ“„ [https://kaggle.com/whitepaper-embeddi...](https://www.kaggle.com/whitepaper-embeddings-and-vector-stores)

â¡ï¸ Complete these code labs on Kaggle:

- Build a RAG question-answering system over custom documents: ğŸ’» [ https://www.kaggle.com/code/markisher... ](https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag)

- Explore text similarity with embeddings: ğŸ’» [ https://www.kaggle.com/code/markisher... ](https://www.kaggle.com/code/markishere/day-2-embeddings-and-similarity-scores)

- Build a neural classification network with Keras using embeddings: ğŸ’» [ https://www.kaggle.com/code/markisher... ](https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras)

---

## Day 3: Generative AI Agents ğŸ¤–

**Resources mentioned in today's livestream:**

- **Agent Building Frameworks:**

    - [LangGraph](https://www.langchain.com/langgraph) ğŸ› ï¸

    - [Firebase GenKit](https://firebase.google.com/docs/genkit) ğŸ› ï¸

    - [Breadboard AI](https://github.com/breadboard-ai/breadboard) ğŸ› ï¸

- **What is RAG?** High-level page from GCP/Vertex: ğŸ“„ [ https://cloud.google.com/use-cases/re... ]

Complete Unit 3: â€œGenerative AI Agentsâ€:

â¡ï¸ Listen to the summary podcast episode: ğŸ§ [Whitepaper Companion Podcast - Agents](https://www.youtube.com/watch?v=...)

â¡ï¸ Read the â€œGenerative AI Agentsâ€ whitepaper: ğŸ“„ [ https://www.kaggle.com/whitepaper-agents ](https://www.kaggle.com/whitepaper-agents)

â¡ï¸ Complete these code labs on Kaggle:

- Talk to a database with function calling: ğŸ’» [ https://www.kaggle.com/code/markisher... ](https://www.kaggle.com/code/markishere/day-3-function-calling-with-the-gemini-api)

- Build an agentic ordering system in LangGraph: ğŸ’» [ https://www.kaggle.com/code/markisher... ](https://www.kaggle.com/code/markishere/day-3-building-an-agent-with-langgraph/)

---

## Day 4: Domain-Specific LLMs ğŸ·ï¸

Complete Unit 4: â€œDomain-Specific LLMsâ€:

â¡ï¸  Listen to the summary podcast episode: ğŸ§ [Whitepaper Companion Podcast - Solving Domain-Specific Problems](https://www.youtube.com/watch?v=b1a4ZOQ8XdI)

â¡ï¸ Read the â€œSolving Domain-Specific Problems Using LLMsâ€ whitepaper: ğŸ“„ [ https://www.kaggle.com/whitepaper-sol... ](https://www.kaggle.com/whitepaper-solving-domains-specific-problems-using-llms)

â¡ï¸ Complete these code labs on Kaggle:

-  Use Google Search data in generation: ğŸŒ [ https://www.kaggle.com/code/markisher... ](https://www.kaggle.com/code/markishere/day-4-google-search-grounding)

    *Note: Grounding with Google Search has been released as a limited launch and is not available in all locations. The EEA, UK, and CH regions will be supported at a later date.*

- Tune a Gemini model for a custom task: ğŸ’» [ https://www.kaggle.com/code/markisher... ](https://www.kaggle.com/code/markishere/day-4-fine-tuning-a-custom-model)

---

## Day 5: MLOps for Generative AI âš™ï¸

**Resources:**

- **Neptune:** ğŸ› ï¸ [https://github.com/google-deepmind/ne...](https://github.com/google-deepmind/neptune)

- **Gecko: Text-to-Image Evaluation:** ğŸ“„ [Link](https://arxiv.org/abs/2404.16820)

- **Google Cloud Vertex AI:** â˜ï¸ [Vertex AI](https://cloud.google.com/vertex-ai/)

- **BigQuery:** ğŸ“Š [Link](https://cloud.google.com/bigquery/)

- **Vertex AI GenAI Evaluation Service:** ğŸ› ï¸ [https://cloud.google.com/vertex-ai/ge...](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview)

Complete Unit 5: â€œMLOps for Generative AIâ€:

â¡ï¸  Listen to the summary podcast episode: ğŸ§ [Whitepaper Companion Podcast - Operationalizing Generative AI](https://www.youtube.com/watch?v=k9S6IhiUUj4)

â¡ï¸ Read the â€œMLOps for Generative AIâ€ whitepaper: ğŸ“„ [https://www.kaggle.com/whitepaper-ope...]()

â¡ï¸ No code lab for today! We will do a code walkthrough and live demo of the [E2E Gen AI App Starter Pack](https://goo.gle/e2e-gen-ai-app-starter), a resource created to make MLOps for Gen AI easier and accelerate the path to production. Please go through the repository in advance.

